KnitPack repository format
==========================

Bazaar 0.92 adds a new format (experimental at first) implemented in
``bzrlib.repofmt.pack_repo.py``.  

This format provides a knit-like interface which is quite compatible
with knit format repositories: you can get a VersionedFile for a
particular file-id, or for revisions, or for the inventory, even though
these do not correspond to single files on disk.

The on-disk format is that the repository directory contains these
files and subdirectories:

==================== =============================================
packs/               completed readonly packs
indices/             indices for completed packs
upload/              temporary files for packs currently being 
                     written
obsolete_packs/      packs that have been repacked and are no 
                     longer normally needed
pack-names           index of all live packs
lock/                lockdir
==================== =============================================

This is implemented on top of pack files, which are written once from
start to end, then left alone.  A pack consists of a body file, plus
several index files.  There are four index files for each pack, which
have the same basename and an extension indicating the purpose of the
index:

==== ========== ======================== ==========================
extn Purpose    Key                      References
==== ========== ======================== ==========================
.tix File texts ``file_id, revision_id`` compression base,
                                         per-file parents
.six Signatures ``revision_id,``         -
.rix Revisions  ``revision_id,``         revision parents
.iix Inventory  ``revision_id,``         compression base,
                                         revision parents
==== ========== ======================== ==========================

Indices are stored as sorted files on disk.  Each line is one record,
and contains:

 * key fields
 * a value string - for all these indices, this is an ascii decimal pair
   of "offset length" giving the position of the refenced data within 
   the pack body file
 * a list of zero or more reference lists

The reference lists let a graph be stored within the index.  Each
reference list entry points to another entry in the same index.  The
references are represented as a byte offset for the target within the
index file.

When a compression base is given, it indicates that the body of the text
or inventory is a forward delta from the referenced revision.  The
compression base list must have length 0 or 1.

The data content for each record is a knit data chunk.  The knits are
always unannotated - the annotations must be generated when needed.
(We'd like to cache/memoize the annotations.)  The data hunks can be
moved between packs without needing to recompress them.

There can also be index entries with a value of 'a' for absent.  These
records exist just to be pointed to in a graph.  This is used, for
example, to give the revision-parent pointer when the parent revision is
in a previous pack.

It is not possible to regenerate an index from the body file, because it
contains information stored in the knit index that's not in the body.
(In particular, the per-file graph is only stored in the index.) 
We would like to change this in a future format

The lock is a regular LockDir lock.  The lock is only held for a much
reduced scope, while updating the pack-names file.  The bulk of the
insertion can be done without the repository locked.  This is an
implementation detail; the repository user should still call
``repository.lock_write`` at the regular time but be aware this does not
correspond to a physical mutex. 

Read locks control caching but do not affect writers.

The newly-added repository write group concept is very important to
KnitPack repositories.  When ``start_write_group`` is called, a new
temporary pack is created and all modifications to the repository will 
go into it until either ``commit_write_group`` or ``abort_write_group``
is called, at which time it is either finished and moved into place or
discarded respectively.  Write groups cannot be nested, only one can be
underway at a time on a Repository instance and they must occur within a
write lock.

Normally the data for each revision will be entirely within a single
pack but this is not required.

When a pack is finished, it gets a final name based on the md5 of all
the data written into the pack body file.

The ``pack-names`` file gives the list of all finished non-obsolete
packs.  (This should always be the same as the list of files in the
``packs/`` directory, but the file is needed for readonly http clients
that can't easily list directories, and it includes other information.)
The ``pack-names`` file can be recreated by looking at the packs on disk.
As well as the list of names, it also contains the size in bytes of th`d

In normal use, one pack will be created for each commit to a repository.
This would build up to an inefficient number of files over time, so a
``repack`` operation is available to recombine them, by producing larger
files containing data on multiple revisions.  This can be done manually
by running ``bzr pack``, and it also may happen automatically when a
write group is committed.

The repacking strategy used at the moment tries to balance not doing too
much work during commit with not having too many small files left in the
repository.  The algorithm is roughly this: the total number of
revisions in the repository is expressed as a decimal number, e.g.
"532".  Then we'll repack until we have five packs containing a hundred
revisions each, three packs containing ten revisions each, and two packs
with single revisions.  This means that each revision will normally
initially be created in a single-revision pack, then moved to a
ten-revision pack, then to a 100-pack, and so on.




Sketched notes on packs
~~~~~~~~~~~~~~~~~~~~~~~

 fast pull:

 - query and pull revs
 - query and pull references
 - query and pull further references
 - etc
 - for now:
 - query and pull revs and sigs
 - query and pull inventory with cache on
 - query and pull all of texts

 pack:

  - two modes - complete and incremental
  - complete:

    - grab all revisions, regenerate deltas, etc.
    - may want data grouping by recreation not by
      origin. i.e. 'tip' pack has everything to construct
      revision -1, older packs have data that is not needed
      for current revisions.

  - incremental:

    - leave most data untouched most of the time
    - therefore can't really promote old data to be current.
    - possible approach:

      upper number of packs = sum of digits in the commit count
      so we need to combine packs whenever a commit rolls over a power
      of 10 - at most once every 10 commit, possibly much less.
      exponential backoff of commits per pack file. So the number of
      revisions per pack is log10(revisions in repository).
      up to 10 commits - 1 revision per pack
      up to 100 commits - 2 revisions per pack
      10 commits - 1 packs, 100 commits - 2 packs
 
      - count number of 1-revision packs, if 10 group them
        into one larger pack.
      - count number of 10-unit packs. if 10, group those 
        into one larger pack.
      - etc

      this approach reads 10 entire packs every 10 commits,
      100 every 100, 1000 every 1000

  vim: tw=72 ft=rest expandtab
